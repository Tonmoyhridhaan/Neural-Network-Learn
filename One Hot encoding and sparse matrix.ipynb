{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Lab-7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG5v_3LHniu6"
      },
      "source": [
        "sentence_bn = [' আমরা আজ ল্যাব ক্লাস এ নিউরাল নেটওয়ার্ক  প্রয়োগ করব','আমাদের প্রোগ্রামিং অনেক ভালো লাগে' ,'আমরা সবাই এই  কোর্সে ভালো মার্ক পেতে চাই']\n",
        "sentence_en = ['We do not know how to implement a neural network', 'We don\\'t like programming t all','we are in great doubt about our marks in this course']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osgtQlaYrl09",
        "outputId": "dba3fbec-4f07-4c60-eb0e-ac192e323920"
      },
      "source": [
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ASkQNArsBUf",
        "outputId": "c15d5605-49a1-4295-fc07-37f163ebc440"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "# vec.fit(sentence_en)\n",
        "model=vec.fit_transform(sentence_en)\n",
        "vec.vocabulary_\n",
        "vocab_list = vec.get_feature_names()\n",
        "print(vocab_list)\n",
        "# print(model.toarray())\n",
        "count_list=model.toarray().sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['about', 'all', 'are', 'course', 'do', 'don', 'doubt', 'great', 'how', 'implement', 'in', 'know', 'like', 'marks', 'network', 'neural', 'not', 'our', 'programming', 'this', 'to', 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDzWtj0bvcuE",
        "outputId": "5f31b52d-f821-4671-d3de-f1cbb29c148b"
      },
      "source": [
        "print(dict(zip(vocab_list,count_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'about': 1, 'all': 1, 'are': 1, 'course': 1, 'do': 1, 'don': 1, 'doubt': 1, 'great': 1, 'how': 1, 'implement': 1, 'in': 2, 'know': 1, 'like': 1, 'marks': 1, 'network': 1, 'neural': 1, 'not': 1, 'our': 1, 'programming': 1, 'this': 1, 'to': 1, 'we': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr9seCN3v50k",
        "outputId": "eb4643e6-ec32-479a-d0c5-945c603bee06"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "vec_new = CountVectorizer(encoding='utf-8', tokenizer=word_tokenize)\n",
        "vec_new.fit(sentence_bn)\n",
        "\n",
        "vocab_list_bn = vec_new.get_feature_names()\n",
        "print(vocab_list_bn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['অনেক', 'আজ', 'আমরা', 'আমাদের', 'এ', 'এই', 'করব', 'কোর্সে', 'ক্লাস', 'চাই', 'নিউরাল', 'নেটওয়ার্ক', 'পেতে', 'প্রোগ্রামিং', 'প্রয়োগ', 'ভালো', 'মার্ক', 'লাগে', 'ল্যাব', 'সবাই']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQQYn_zOxkgP",
        "outputId": "98db2560-2495-48f5-fc36-5a1104e62b85"
      },
      "source": [
        "# Tokenazination\n",
        "tokenized_bn = []\n",
        "\n",
        "sentence_bn = sentence_bn + ['এইখানে আমরা নতুন আরো একটি বাক্য রাখলাম']\n",
        "\n",
        "for sent in sentence_bn:\n",
        "  tokenized_sent = word_tokenize(sent)\n",
        "  tokenized_bn.append(tokenized_sent)\n",
        "\n",
        "print(tokenized_bn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['আমরা', 'আজ', 'ল্যাব', 'ক্লাস', 'এ', 'নিউরাল', 'নেটওয়ার্ক', 'প্রয়োগ', 'করব'], ['আমাদের', 'প্রোগ্রামিং', 'অনেক', 'ভালো', 'লাগে'], ['আমরা', 'সবাই', 'এই', 'কোর্সে', 'ভালো', 'মার্ক', 'পেতে', 'চাই'], ['এইখানে', 'আমরা', 'নতুন', 'আরো', 'একটি', 'বাক্য', 'রাখলাম']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4mO7CFd_lFV",
        "outputId": "8d548f25-958e-40a2-ef7f-2fdc1b4b651b"
      },
      "source": [
        "# Lab Task:\n",
        "for x in vocab_list_bn:\n",
        "  cnt=0\n",
        "  for y in tokenized_bn:\n",
        "    for z in y:\n",
        "      if x==z:\n",
        "        cnt+=1\n",
        "  print(x+\" occurs \",cnt,\" Times\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "অনেক occurs  1  Times\n",
            "আজ occurs  1  Times\n",
            "আমরা occurs  3  Times\n",
            "আমাদের occurs  1  Times\n",
            "এ occurs  1  Times\n",
            "এই occurs  1  Times\n",
            "করব occurs  1  Times\n",
            "কোর্সে occurs  1  Times\n",
            "ক্লাস occurs  1  Times\n",
            "চাই occurs  1  Times\n",
            "নিউরাল occurs  1  Times\n",
            "নেটওয়ার্ক occurs  1  Times\n",
            "পেতে occurs  1  Times\n",
            "প্রোগ্রামিং occurs  1  Times\n",
            "প্রয়োগ occurs  1  Times\n",
            "ভালো occurs  2  Times\n",
            "মার্ক occurs  1  Times\n",
            "লাগে occurs  1  Times\n",
            "ল্যাব occurs  1  Times\n",
            "সবাই occurs  1  Times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01EH4DlNxMTu"
      },
      "source": [
        "# Manually Implement the Number of Occurences of each words in the sentence_bn dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZE5QgSH1VbR",
        "outputId": "8486c055-406b-4125-9ce8-addac70a2687"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "std_names = ['জিয়াদ','নয়ন','কিশোর' ,'বিলাস' ,'ইমতিয়াজুল' ,'মনিরুল','নয়ন']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "name_labels = encoder.fit_transform(std_names)\n",
        "\n",
        "# dense represnetation\n",
        "print(name_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 3 1 4 0 5 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35_q9-gG3eDW",
        "outputId": "0525c294-dcad-421f-ad26-3cd4af7fe884"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "name_labels = name_labels.reshape((7,1))\n",
        "\n",
        "sparse_rep = encoder.fit_transform(name_labels).toarray()\n",
        "\n",
        "print(sparse_rep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}