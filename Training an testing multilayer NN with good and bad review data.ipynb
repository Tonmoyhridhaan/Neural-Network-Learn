{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Lab-8_Spring_2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4pk2muJSvYz",
        "outputId": "d3cc628b-7931-4f8e-fd66-ee51ff1dbbb8"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbHHVXbKXc4z"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(1000, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpWAb8YXX44N",
        "outputId": "4898b2f7-7c08-4d35-f189-3ff91bca1504"
      },
      "source": [
        "result = embedding_layer(tf.constant([1, 2, 3]))\n",
        "result.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04308686,  0.0207612 , -0.04706863, -0.02214487,  0.02777444],\n",
              "       [ 0.01114864, -0.02188963,  0.02224754, -0.00815169, -0.04206406],\n",
              "       [ 0.04927727, -0.03924382,  0.0156295 ,  0.00562941, -0.01282211]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEzJFRzbYZ71",
        "outputId": "fab5d4ce-4293-4724-a24b-55bb2f1d9231"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "sentence = ['‡¶è‡¶á ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶™‡¶æ‡¶ì‡ßü‡¶æ ‡¶∏‡¶Ç‡¶¨‡¶æ‡¶¶‡ßá ‡¶ú‡¶æ‡¶®‡¶æ ‡¶ó‡ßá‡¶≤‡ßã ‡¶¶‡ßá‡¶∂ ‡¶è‡¶∞ ‡¶ï‡¶∞‡ßã‡¶®‡¶æ ‡¶™‡¶∞‡¶ø‡¶∏‡ßç‡¶•‡¶ø‡¶§‡¶ø‡¶∞ ‡¶â‡¶®‡ßç‡¶®‡¶§‡¶ø ‡¶π‡ßü‡ßá‡¶õ‡ßá', \n",
        "            '‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶æ‡¶ú‡ßá ‡¶Æ‡ßÅ‡¶ñ‡ßã‡¶∂‡¶ß‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶Ö‡¶≠‡¶æ‡¶¨ ‡¶®‡¶æ‡¶á', \n",
        "            '‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¶‡¶ø‡¶® ‡¶¶‡¶ø‡¶® ‡¶¨‡ßã‡¶ï‡¶æ‡¶∞ ‡¶∞‡¶æ‡¶ú‡ßç‡¶Ø‡ßá ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶∏‡¶ø‡¶§ ‡¶π‡¶ö‡ßç‡¶õ‡¶ø']\n",
        "\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences(sentence)\n",
        "\n",
        "sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],\n",
              " [14, 15, 16, 17, 18, 19],\n",
              " [20, 1, 1, 21, 22, 23, 24]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G10BENsTafAa",
        "outputId": "ffb956a1-ed73-4638-c23a-62ea439f6610"
      },
      "source": [
        "result = embedding_layer(tf.constant(sequence[0]))\n",
        "result.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.01635168,  0.04967446, -0.00023917, -0.0346488 ,  0.04874494],\n",
              "       [ 0.0006019 ,  0.03718195, -0.00013598,  0.00538623,  0.0242821 ],\n",
              "       [ 0.04910569, -0.04896344,  0.00352651,  0.02241186, -0.00985166],\n",
              "       [-0.02418989,  0.01568817, -0.01916443, -0.02960224, -0.04355192],\n",
              "       [-0.00989994,  0.04398192, -0.029193  , -0.04610256, -0.01049926],\n",
              "       [-0.01412474,  0.01774978, -0.04547737,  0.0155565 ,  0.04661223],\n",
              "       [ 0.00237618,  0.04564855, -0.04798998, -0.04732874,  0.01537519],\n",
              "       [ 0.03465958,  0.01110286,  0.00846188, -0.03764268,  0.00877468],\n",
              "       [ 0.03781906, -0.03061415,  0.04977075, -0.02758809, -0.03283403],\n",
              "       [ 0.00988791,  0.04700109, -0.00539299,  0.01915895,  0.0446023 ],\n",
              "       [ 0.0458385 ,  0.00985735,  0.02358161,  0.02022591,  0.00947325],\n",
              "       [-0.02238098, -0.04811947,  0.04313776, -0.0339369 ,  0.02638704]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF357AqLhRHO"
      },
      "source": [
        "from numpy import array\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Embedding, Dense, LSTM, Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cICBB2hTh5r7"
      },
      "source": [
        "# Real Life Example of Classification\n",
        "\n",
        "train_ex = ['‡¶™‡¶£‡ßç‡¶Ø ‡ßß‡ß¶‡ß¶% ‡¶Ö‡¶∞‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶Ü‡¶∏‡¶õ‡ßá ‡¶ì‡¶ü‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶ï‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶®‡¶æ‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡ß™‡ß®',\n",
        "             '‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡ßá‡¶∞ ‡¶õ‡¶ø‡¶≤ ‡¶è‡¶ï‡¶ü‡ßÅ ‡¶≠‡¶æ‡¶∞‡ßÄ ‡¶Æ‡¶®‡ßá ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶ú‡ßÅ‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶∂‡¶ï‡ßç‡¶§‡•§ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü‡¶ü‡¶ø ‡¶†‡¶ø‡¶ï ‡¶Ü‡¶õ‡ßá ‡¶Ø‡¶æ ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡¶æ‡¶á ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø  ‡¶ì‡¶≠‡¶æ‡¶∞‡¶Ö‡¶≤ ‡¶≠‡¶æ‡¶≤‡ßã',\n",
        "             '‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§, ‡¶†‡¶ø‡¶ï ‡¶Ø‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶ö‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ ‡¶§‡ßá‡¶Æ‡¶®‡¶ü‡¶ø ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡¶ø‡•§‡•§ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡•§',\n",
        "             '‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£...‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡•§ ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§',\n",
        "             '‡¶¨‡ßá‡¶∂‡¶ø ‡¶¨‡¶≤‡¶¨‡¶®‡¶æ ‡¶è‡¶ï‡¶ï‡¶•‡¶æ‡ßü ‡¶è‡¶ï‡¶∂‡¶§‡ßá ‡¶è‡¶ï‡¶∂‡•§ ‡¶¶‡¶æ‡¶Æ ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶ñ‡ßÅ‡¶¨‡¶á‡¶∏‡ßÅ‡¶®‡ßç‡¶¶‡¶∞ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶ï‡ßá‡•§',\n",
        "             '‡¶ñ‡ßÅ‡¶¨ ‡¶è‡¶ï‡¶ü‡¶æ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶≤‡¶æ ‡¶ö‡¶≤‡ßá ‡¶®‡¶æ‡•§ ‡¶ö‡¶æ‡¶á‡¶≤‡¶æ‡¶Æ ‡ß™‡ßß ‡¶Ü‡¶∞ ‡¶¶‡¶ø‡¶≤‡ßã ‡ß™‡ß¶‡•§‡•§‡¶ì‡¶®‡¶æ‡¶∞‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞‡¶æ‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶∞‡¶ø‡¶≠‡¶ø‡¶â ‡¶¶‡ßá‡ßü ‡¶ï‡¶æ‡¶∏‡ßç‡¶ü‡¶Æ‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶®‡ßç‡¶Ø‡ßá',\n",
        "             '‡¶π‡¶æ‡¶ü‡¶æ‡¶∞ ‡¶∏‡¶Æ‡ßü ‡¶Ö‡¶®‡ßá‡¶ï ‡¶Ü‡¶® ‡¶á‡¶ú‡¶ø ‡¶™‡¶æ ‡¶¨‡¶æ‡¶ï‡¶æ‡¶§‡ßá ‡¶™‡ßç‡¶∞‡¶¨‡ßç‡¶≤‡ßá‡¶Æ ‡¶π‡ßü',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶∞ ‡¶Æ‡¶§ ‡¶è‡¶á ‡¶∞‡¶ï‡¶Æ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡ßü ‡¶®‡¶æ',\n",
        "             '‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶§‡ßã ‡¶∏‡¶¨‡¶∏‡¶Æ‡ßü‡¶á ‡¶≠‡¶æ‡¶≤‡ßã ‡¶¨‡¶æ‡¶ü ‡¶°‡ßá‡¶≤‡¶ø‡¶≠‡¶æ‡¶∞‡¶ø ‡¶¨‡¶æ‡¶ú‡ßá ‡¶õ‡¶ø‡¶≤‡ßãüò°üò°üò° ‡¶Ø‡ßá‡¶¶‡¶ø‡¶® ‡¶¶‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶•‡¶æ ‡¶è‡¶∞ ‡ß® ‡¶¶‡¶ø‡¶® ‡¶™‡¶∞ ‡¶¶‡¶ø‡¶õ‡ßá...',\n",
        "             '‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶∏‡ßá‡¶≤‡¶æ‡¶∞‡•§ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶¶‡¶ø‡ßü‡¶æ ‡¶¨‡¶≤‡ßç‡¶≤‡¶æ‡¶Æ ‡¶∏‡¶æ‡¶á‡¶ú ‡¶Ø‡¶æ‡¶§‡ßá ‡¶â‡¶≤‡ßç‡¶ü‡ßã‡¶™‡¶æ‡¶≤‡ßç‡¶ü‡¶æ ‡¶®‡¶æ ‡¶Ü‡¶∏‡ßá‡•§ ‡¶ï‡ßá‡¶â ‡¶Ö‡¶∞‡¶°‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§‡•§'\n",
        "             ]\n",
        "\n",
        "# Reviews -- negative = 0 || positive = 1 (class/labels)\n",
        "train_label = array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iBFjv-kbkdLB",
        "outputId": "90c86900-ee06-4d53-ad14-c0217f7e9cdd"
      },
      "source": [
        "train_ex[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£...‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú‡•§‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏‡•§ ‡¶Ö‡¶∞‡¶ø‡¶ú‡¶ø‡¶®‡¶æ‡¶≤ ‡¶™‡ßç‡¶∞‡ßã‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶¶‡ßá‡¶ì‡ßü‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡•§'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OWv_Zwjkjy-",
        "outputId": "164329a3-97b4-4393-bded-1c9b08f8ef9b"
      },
      "source": [
        "# tokenization and converting words into sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_ex)\n",
        "dense_train_ex = tokenizer.texts_to_sequences(train_ex)\n",
        "\n",
        "dense_train_ex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[14, 15, 16, 17, 5, 6, 18, 19, 20, 21, 22, 7, 5, 23, 24],\n",
              " [8, 25, 26, 27, 28, 29, 30, 8, 9, 31, 32, 10, 33, 34, 11, 35, 36, 37, 1],\n",
              " [38, 39, 10, 40, 11, 41, 42, 2, 3, 2, 43],\n",
              " [44, 2, 45, 46, 47, 4, 48, 49],\n",
              " [50, 51, 52, 53, 54, 55, 56, 57, 4, 2, 58, 9, 59, 60],\n",
              " [61, 62, 1, 63, 64, 7, 65, 66, 67, 68, 69, 70, 1, 71, 72, 73, 74, 75],\n",
              " [76, 77, 78, 79, 80, 81, 82, 83, 84],\n",
              " [3, 12, 85, 86, 87, 4, 88, 89, 90, 13],\n",
              " [3, 91, 92, 1, 93, 94, 95, 96, 97, 98, 99, 12, 100, 101, 102, 103],\n",
              " [104, 105, 106, 107, 108, 6, 109, 110, 13, 111, 112, 113, 114, 115, 116, 117]]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AgdiZbTnIfZ",
        "outputId": "34080703-850f-41df-f9f2-1c777b404e7c"
      },
      "source": [
        "# padding the training documents in order to make them equal length\n",
        "MAX_LENGTH = 16\n",
        "\n",
        "padded_train_ex = pad_sequences(dense_train_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "for pd_sen in padded_train_ex:\n",
        "  print(pd_sen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 15 16 17  5  6 18 19 20 21 22  7  5 23 24  0]\n",
            "[27 28 29 30  8  9 31 32 10 33 34 11 35 36 37  1]\n",
            "[38 39 10 40 11 41 42  2  3  2 43  0  0  0  0  0]\n",
            "[44  2 45 46 47  4 48 49  0  0  0  0  0  0  0  0]\n",
            "[50 51 52 53 54 55 56 57  4  2 58  9 59 60  0  0]\n",
            "[ 1 63 64  7 65 66 67 68 69 70  1 71 72 73 74 75]\n",
            "[76 77 78 79 80 81 82 83 84  0  0  0  0  0  0  0]\n",
            "[ 3 12 85 86 87  4 88 89 90 13  0  0  0  0  0  0]\n",
            "[  3  91  92   1  93  94  95  96  97  98  99  12 100 101 102 103]\n",
            "[104 105 106 107 108   6 109 110  13 111 112 113 114 115 116 117]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu9NqNL9n3Zb",
        "outputId": "03986fc9-b13a-4dc1-f0c9-fcbc28cb288a"
      },
      "source": [
        "# Model Declaration\n",
        "VOCAB_SIZE = 118\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding Layer\n",
        "embedding_layer = Embedding(input_dim=VOCAB_SIZE, output_dim=8, input_length=MAX_LENGTH)\n",
        "model.add(embedding_layer)\n",
        "\n",
        "# # Flatten Layer\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(units=160, activation='relu'))\n",
        "# model.add(Dense(units=80, activation='relu'))\n",
        "# model.add(Dense(units=40, activation='relu'))\n",
        "# model.add(Dense(units=10, activation='relu'))\n",
        "\n",
        "# LSTM - for better performance\n",
        "# model.add(LSTM(units=128))\n",
        "\n",
        "# Bidirectional LSTM\n",
        "forward_layers = LSTM(units=128, return_sequences=False)\n",
        "backward_layers = LSTM(units=128, return_sequences=False, go_backwards=True)\n",
        "model.add(Bidirectional(layer=forward_layers, backward_layer=backward_layers))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['acc'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_14 (Embedding)     (None, 16, 8)             944       \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 256)               140288    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 141,489\n",
            "Trainable params: 141,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InvCtAjsrxPX",
        "outputId": "7d68add2-48a7-4cf2-992d-dd9b5c8fa0c4"
      },
      "source": [
        "model.fit(padded_train_ex, train_label, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.2505 - acc: 0.3000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2501 - acc: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2498 - acc: 0.7000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2494 - acc: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2489 - acc: 0.6000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2483 - acc: 0.9000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2476 - acc: 1.0000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2467 - acc: 1.0000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2456 - acc: 0.9000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2442 - acc: 0.9000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2424 - acc: 0.9000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2401 - acc: 0.9000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2372 - acc: 1.0000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2334 - acc: 1.0000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2283 - acc: 1.0000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2216 - acc: 1.0000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2127 - acc: 1.0000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2006 - acc: 1.0000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1844 - acc: 1.0000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1630 - acc: 1.0000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1354 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1022 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0665 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0357 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0151 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0015 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.1930e-04 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.1207e-04 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.1387e-04 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1440e-05 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.2093e-05 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5723e-05 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4721e-05 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0572e-04 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.8886e-05 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.6298e-06 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.8140e-07 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7700e-07 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4021e-06 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.5557e-06 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1634e-05 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.1513e-06 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.5375e-07 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1043e-07 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.2828e-07 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6203e-07 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.6455e-07 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1606e-06 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.8761e-06 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.2241e-06 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9496e-06 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.0531e-06 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0061e-06 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.1257e-06 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.5372e-07 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1762e-07 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0060e-07 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.5880e-08 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 6.9318e-08 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.7372e-08 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.6722e-08 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.6319e-08 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5784e-08 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.4959e-08 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.3830e-08 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.2382e-08 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.0659e-08 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.8703e-08 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.6568e-08 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.4329e-08 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.2028e-08 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.9722e-08 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.7415e-08 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5172e-08 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3017e-08 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.0948e-08 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8998e-08 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7152e-08 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5421e-08 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.3810e-08 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2309e-08 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0918e-08 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9625e-08 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8431e-08 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7332e-08 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6314e-08 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.5375e-08 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4508e-08 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3703e-08 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2967e-08 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.2284e-08 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1641e-08 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.1057e-08 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0512e-08 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.0007e-08 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.9536e-08 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9094e-08 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8689e-08 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.8310e-08 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8d7dd792d0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBAB4FT4sKO9",
        "outputId": "251bfa6c-8f75-4a9c-cb9f-d91e5bc4239e"
      },
      "source": [
        "# Testing\n",
        "test_ex = ['‡¶¶‡¶æ‡¶Æ‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶π‡¶≤‡ßá‡¶ì ‡¶Æ‡¶æ‡¶®‡ßá ‡¶≠‡¶æ‡¶≤‡ßã, ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶è‡¶™‡ßá‡¶ï‡ßç‡¶∏ ‡¶è‡¶¨‡¶Ç ‡¶¶‡¶æ‡¶∞‡¶æ‡¶ú ‡¶ï‡ßá', \n",
        "           '‡¶ú‡ßÅ‡¶§‡¶æ‡¶ü‡¶ø ‡¶π‡¶æ‡¶§‡ßá ‡¶™‡ßá‡ßü‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á ‡¶¨‡¶ø‡¶∏‡ßç‡¶Æ‡¶ø‡¶§', \n",
        "           '‡¶è‡¶ï‡¶¶‡¶Æ ‡¶¨‡¶æ‡¶ú‡ßá, ‡¶Æ‡¶®‡ßá ‡¶π‡¶ö‡ßç‡¶õ‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶æ‡¶∞‡¶ø‡¶§ ‡¶π‡¶≤‡¶æ‡¶Æ üò°',\n",
        "           '‡¶è‡¶§‡ßã ‡¶´‡¶æ‡¶≤‡¶§‡ßÅ ‡¶™‡ßç‡¶∞‡¶°‡¶æ‡¶ï‡ßç‡¶ü ‡¶™‡¶¨‡ßã ‡¶Ü‡¶∂‡¶æ ‡¶ï‡¶∞‡¶ø ‡¶®‡¶ø']\n",
        "\n",
        "# tokenization and converting words into sequence\n",
        "dense_test_ex = tokenizer.texts_to_sequences(test_ex)\n",
        "\n",
        "# padding the test documents\n",
        "padded_test_ex = pad_sequences(dense_test_ex, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "prediction = model.predict(padded_test_ex)\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.99979025]\n",
            " [0.9997021 ]\n",
            " [0.38281277]\n",
            " [0.27359986]]\n"
          ]
        }
      ]
    }
  ]
}